---
title: "The evolution of badges of status with learners"
author: "Andrés Quiñones"
bibliography: SocialMorphCue.bib
output: 
    beamer_presentation: 
      fig_caption: yes
      keep_tex: yes
header-includes: 
    \usepackage{float}
    \usepackage{multicol}
    \usepackage{amsmath} 
    \usepackage{graphicx}
    \usepackage{array}
                #\floatplacement{figure}{H}
---



```{r loadData, echo=FALSE,include=FALSE,warning=FALSE,message=FALSE}
# Required libraries -----------------------------------------------------------

library(here)
here()
source(here("AccFunc.R"))
# Scenario to be plotted - corresponds to folders where simulations are stored
scenario<-"mutType"
(listTest<-list.files(here("Simulations",paste0(scenario,"_"))))
(evolList<-grep(".txt",grep("evol",listTest,value=TRUE),value=TRUE))
(indList<-grep("ind",listTest,value=TRUE))

fileId<-1
evol<-fread(here("Simulations",paste0(scenario,"_"),evolList[fileId]))
pop<-fread(here("Simulations",paste0(scenario,"_"),indList[fileId]))
evolStats<-evol[,.(m.freqGenHawk=mean(freqGenHawks),
                   upIQR.freqGenHawk=fivenum(freqGenHawks)[4],
                   lowIQR.freqGenHawk=fivenum(freqGenHawks)[2],
                   m.freqGenDove=mean(freqGenDove),
                   upIQR.freqGenDove=fivenum(freqGenDove)[4],
                   lowIQR.freqGenDove=fivenum(freqGenDove)[2],
                   m.freqEval=mean(freqGenEval),
                   upIQR.freqGenEval=fivenum(freqGenEval)[4],
                   lowIQR.freqGenEval=fivenum(freqGenEval)[2], 
                   m.freqFenHawk=mean(freqFenHawks),
                   upIQR.freqFenHawk=fivenum(freqFenHawks)[4],
                   lowIQR.freqFenHawk=fivenum(freqFenHawks)[2],
                   m.freqFenDove=mean(freqFenDoves),
                   upIQR.freqFenDove=fivenum(freqFenDoves)[4],
                   lowIQR.freqFenDove=fivenum(freqFenDoves)[2],
                   m.meanAlpha=mean(meanAlpha),
                   upIQR.alpha=fivenum(meanAlpha)[4],
                   lowIQR.alpha=fivenum(meanAlpha)[2],
                   m.meanBeta=mean(meanBeta),
                   upIQR.beta=fivenum(meanBeta)[4],
                   lowIQR.beta=fivenum(meanBeta)[2],
                   m.freqHH = mean(freqHH),
                   m.freqHD = mean(freqHD),
                   m.freqDD = mean(freqDD),
                   upIQR.freqHH = fivenum(freqHH)[4],
                   upIQR.freqHD = fivenum(freqHD)[4],
                   upIQR.freqDD = fivenum(freqDD)[4],
                   lowIQR.freqHH = fivenum(freqHH)[4],
                   lowIQR.freqHD = fivenum(freqHD)[2],
                   lowIQR.freqDD = fivenum(freqDD)[2],
                   m.weightAct_0=mean(WeightAct_0),
                   m.weightAct_1=mean(WeightAct_1),
                   m.weightAct_2=mean(WeightAct_2),
                   m.weightAct_3=mean(WeightAct_3),
                   m.weightAct_4=mean(WeightAct_4),
                   m.weightCrit_0=mean(WeightCrit_0),
                   m.weightCrit_1=mean(WeightCrit_1),
                   m.weightCrit_2=mean(WeightCrit_2),
                   m.weightCrit_3=mean(WeightCrit_3),
                   m.weightCrit_4=mean(WeightCrit_4)),by=time]
# Extract means and IQR for the dynamic variables ------------------------------

popStats<-pop[, as.list(unlist(lapply(.SD, 
                                      function(x) list(m = mean(x),
                                                       upIQR = fivenum(x)[4],
                                                       downIQR = fivenum(x)[2]
                                      )))),
              by = time, 
              .SDcols=c("Quality","alpha","beta","Badge","nInteract","WeightAct_0",
                        "WeightAct_1","WeightAct_2","WeightAct_3","WeightAct_4",
                        "WeightCrit_0","WeightCrit_1","WeightCrit_2",
                        "WeightCrit_3","WeightCrit_4")]


# knitr::include_graphics("Simulations/mutType_/basicHawkDove.png")
```

## The Hawk-Dove game

Individuals have one of two genetically determined phenotypic strategies. _Hawks_ are willing to start a conflict over resources, while _doves_ prefer to stand down in the hope to share the resource without an aggressive contest.

```{r,echo=FALSE,fig.align="center",out.width='50%'}
knitr::include_graphics("Images//HDgame.jpeg")
```

## The hawk-dove game

\begin{align*}
w_H &= p_H \frac{V-C}{2}+(1-p_h) V\\
w_D &= p_H 0 + (1-p_H)\frac{V}{2}
\end{align*}
\vspace{-0.8cm}
```{r, echo=FALSE,fig.align="center", out.width = '55%'}
knitr::include_graphics("Images//Hawk_dove_plot.png")
```


## The hawk-dove game

```{r, echo=FALSE, fig.cap="\\label{fig:HD_game}Hawk-dove game. Dashed line is the  game theoretical prediction for frequency of hawks.", out.width = '80%'}
knitr::include_graphics("Simulations/mutType_/basicHawkDove.png")
```

## What about signals?

```{r,echo=FALSE,fig.align='center',out.height='80%'}
knitr::include_graphics("Images//hosp_alexandra_mackenzie.jpg")

```


## What about signals?

### When are signals honest?

* Impossible to fake
* Individuals have common interests
* Handicap principle (signal´s cost is proportional to quality)
  + Social costs? 
  
```{r,echo=FALSE, fig.align='center',out.width='100%'}
knitr::include_graphics("Images//social_costs.png")
```

## What about signals?

```{r,echo=FALSE,fig.align='center',out.width='90%'}
knitr::include_graphics("Images//comSystemBot.png")
```

## What about learning?

```{r,echo=FALSE,fig.align='center',out.width='90%'}
knitr::include_graphics("Images//pavlov.jpg")
```

# Associative learning

## Reinforcement learning theory

\begin{columns}[T]
 \column{0.5\linewidth}
 \begin{equation*}
  \Delta V_{t(s)}=\alpha \underbrace{(R_t-V_t)}_\text{prediction error}
  \end{equation*}
  \pause
  \includegraphics[width=1\textwidth]{Images//learn_curve.png}
 \column{0.5\linewidth}
  \pause
  \includegraphics[height=.9\textheight]{Images//predErrorNeur.png}
\end{columns}
  
## Reinforcement learning theory

```{r,echo=FALSE,fig.align='center',out.width='90%'}
knitr::include_graphics("Images//learnUpdate.png")
```

## Environmental states

### Discrete states
\includegraphics[width=0.8\textwidth]{Images//discreteStates.png}

\pause

### Continuos states
\includegraphics[width=0.8\textwidth]{Images//contStates.png}

## Continuos environmental states
\begin{equation*}
  \Delta V_{t(s)}=\alpha \underbrace{(R_t-V_t)}_\text{prediction error}
\end{equation*}

```{r fig2, echo=FALSE, fig.cap="\\label{fig:learning_cartoonRBF}Function approximation for the actor and the critic. Using random values for the responses of each center. Circles show the location of the centers and the maximum response they trigger, while the lines show the total response along the badge size continium.", out.width = '60%'}
knitr::include_graphics("cartoonRBF.png")
```

# Our model

## The hawk-dove game 2.0

\begin{center}
\begin{tabular}{ >{\centering\arraybackslash}p{1cm} | >{\centering\arraybackslash}p{4.5cm} | >{\centering\arraybackslash}p{4.5cm} }
& H & D \\ \hline
H & $p_w V\frac{-C}{2} + (1-p_w) \frac{-C}{2}$ & $V$ \\ \hline
V & $0$ & $\frac{V}{2}$\\
\end{tabular}
\end{center}

\begin{equation*}
p_w=\frac{1}{1+e^{-\beta(Q_i-Q_j)}}
\end{equation*}

```{r,echo=FALSE,fig.align='center',out.width='50%'}
par(plt=posPlot(),las=1)
plot(logist(seq(-1,1,length.out = 1000),alpha = 0,beta = 2)~
       seq(-1,1,length.out = 1000),type="l",xlab="Difference in quality",
     ylab = expression(p[w]),cex.lab=2,lwd=3,col="red",cex.axis=2,ylim=c(0,1))
lines(logist(seq(-1,1,length.out = 1000),alpha = 0,beta = 10)~
       seq(-1,1,length.out = 1000),lwd=3,col="green")
legend("topleft",legend=c(2,10),col=c("red","green"),lwd=3,title = expression(beta),cex=2,bty="n")

```

## Sender Code

\begin{equation*}
s_i = \frac{1}{1+e^{-(\epsilon_i+\gamma_iQ_i)}}
\label{eq:react_norm}
\end{equation*}

```{r,echo=FALSE,fig.align='center',out.width='50%'}
par(plt=posPlot(),las=1)
plot(logist(seq(0,1,length.out = 1000),alpha = 2,beta = 4)~
       seq(0,1,length.out = 1000),type="l",xlab="Quality",
     ylab = expression(p[w]),cex.lab=2,lwd=3,col="red",cex.axis=2,ylim=c(0,1))
lines(logist(seq(0,1,length.out = 1000),alpha = 5,beta = 10)~
       seq(0,1,length.out = 1000),lwd=3,col="green")
legend("topleft",legend=c(4,10),col=c("red","green"),lwd=3,title = expression(gamma),cex=2,bty="n")

```

## Receiver code

\begin{equation*}
  \Delta V_{t(s)}=\alpha (R_t-V_t)
\end{equation*}


```{r, echo=FALSE,fig.align='center', out.width = '60%'}
knitr::include_graphics("cartoonRBF.png")
```

# Results

## When individuals do _NOT_ vary in quality 

```{r , echo=FALSE, fig.align='center',out.width = '80%'}
knitr::include_graphics("Simulations//QualStDv_//hawkDoveLearn.png")
```

## When individuals _DO_ vary in quality

```{r, echo=FALSE, fig.align='center', out.width = '80%'}
knitr::include_graphics("Simulations//QualStDv_//hawkDoveLearn_1.png")
```

## Overal effect of quality variation

```{r fig5, echo=FALSE, fig.align='center', out.width = '80%'}
knitr::include_graphics("Simulations//QualStDv_//effectQualVariance.png")
```

## How does variation among _learners_ look like? 

```{r fig6, echo=FALSE, fig.align='center',out.width = '90%'}
knitr::include_graphics("Simulations//QualStDv_//WeightsVarQualSt.png")
```


## How do the learning dynamics look like?

```{r fig7, echo=FALSE, out.width = '80%'}
knitr::include_graphics("Simulations//mutType_//learnDyn200.png")
```



## How do learners behave when signals are honest?  

```{r fig9, echo=FALSE,out.width='90%',fig.show='hold'}
knitr::include_graphics("Simulations//learHonest_//QualStDv_//weightsVarQualSt.png")
```



## How do learners fare against pure strategies?

```{r fig8, echo=FALSE, fig.align='center', out.width = '80%'}
knitr::include_graphics("Simulations//mutType_//evolDynTypes.png")
```


## What's next? 

* Let reaction norm evolve, under different initial conditions.
* Let learning parmeters evolve
* Let the communication system co-evolve





